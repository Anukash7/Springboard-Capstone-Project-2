{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/sociopath00/random-forest-using-gridsearchcv\n",
    "\n",
    "https://www.kaggle.com/paulantoine/light-gbm-benchmark-0-3692\n",
    "\n",
    "https://www.kaggle.com/datatheque/association-rules-mining-market-basket-analysis\n",
    "\n",
    "\n",
    "order_products__*.csv\n",
    "- These files specify which products were purchased in each order. order_products__prior.csv contains previous order contents for all customers. 'reordered' indicates that the customer has a previous order that contains the product. Note that some orders will have no reordered items. You may predict an explicit 'None' value for orders with no reordered items. See the evaluation page for full details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c conda-forge lightgbm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import itertools as it\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import random\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "from matplotlib import pyplot\n",
    "from datetime import datetime\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import randint\n",
    "from sklearn.metrics import precision_score,recall_score,accuracy_score,f1_score,roc_auc_score\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "priors (32434489, 4): order_id, product_id, add_to_cart_order, reordered\n",
      "orders (3421083, 7): order_id, user_id, eval_set, order_number, order_dow, order_hour_of_day, days_since_prior_order\n",
      "train (1384617, 4): order_id, product_id, add_to_cart_order, reordered\n",
      "add order info to priors\n",
      "computing product features\n",
      "computing user features\n",
      "users shape (206209, 9)\n",
      "split orders : train, test\n",
      "Shape of df_train is : (8474661, 8)\n",
      "Shape of labels array is: 8474661\n",
      "user related features\n",
      "order related features\n",
      "product related features\n",
      "user_X_product related features\n",
      "user related features\n",
      "order related features\n",
      "product related features\n",
      "user_X_product related features\n",
      "(8474661, 43)\n",
      "(4833292, 42)\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/axp/buanalytics/cscust360/dev/Anu/Kaggle\")\n",
    "\n",
    "aisles = pd.read_csv(\"aisles.csv\",parse_dates=True, skiprows=0, na_values = ['NaN'], encoding='utf-8')\n",
    "\n",
    "departments = pd.read_csv(\"departments.csv\",parse_dates=True, skiprows=0, na_values = ['NaN'])\n",
    "\n",
    "priors = pd.read_csv(\"order_products__prior.csv.filepart\",parse_dates=True, skiprows=0, na_values = ['NaN'],\n",
    "                    dtype={'order_id': np.int32,'product_id': np.uint16,'add_to_cart_order': np.int16,'reordered': np.int8})\n",
    "\n",
    "train = pd.read_csv(\"order_products__train.csv.filepart\",parse_dates=True, skiprows=0, na_values = ['NaN'],\n",
    "                   dtype={'order_id': np.int32, 'product_id': np.uint16, 'add_to_cart_order': np.int16,'reordered': np.int8})\n",
    "\n",
    "orders = pd.read_csv(\"orders.csv.filepart\",parse_dates=True, skiprows=0, na_values = ['NaN'],\n",
    "                    dtype={'order_id': np.int32,'user_id': np.int32,'eval_set': 'category','order_number': np.int16,\n",
    "                           'order_dow': np.int8,'order_hour_of_day': np.int8,'days_since_prior_order': np.float32})\n",
    "\n",
    "products = pd.read_csv(\"products.csv.filepart\",parse_dates=True, skiprows=0, na_values = ['NaN'], \n",
    "                       dtype={'product_id': np.uint16, 'order_id': np.int32, 'aisle_id': np.uint8,'department_id': np.uint8},\n",
    "                       usecols=['product_id', 'aisle_id', 'department_id'])\n",
    "\n",
    "# sample_submission = pd.read_csv(\"sample_submission/sample_submission.csv\",parse_dates=True, skiprows=0, na_values = ['NaN'])\n",
    "\n",
    "print('priors {}: {}'.format(priors.shape, ', '.join(priors.columns)))\n",
    "print('orders {}: {}'.format(orders.shape, ', '.join(orders.columns)))\n",
    "print('train {}: {}'.format(train.shape, ', '.join(train.columns)))\n",
    "\n",
    "\n",
    "# Add aisle and department name to the products dataset\n",
    "products = products.merge(aisles, how = 'left', left_on = 'aisle_id', right_on = 'aisle_id')\n",
    "products = products.merge(departments, how = 'left', left_on = 'department_id', right_on = 'department_id')\n",
    "\n",
    "# Add order info to priors\n",
    "print('add order info to priors')\n",
    "priors = priors.merge(orders, how = 'left', left_on='order_id',right_on='order_id')\n",
    "\n",
    "priors['user_buy_product_times'] = priors.groupby(['user_id', 'product_id']).cumcount()+1\n",
    "priors['prod_buy_first_time'] = np.where(priors['user_buy_product_times'] == 1, 1, 0)\n",
    "priors['prod_buy_second_time'] = np.where(priors['user_buy_product_times'] == 2, 1, 0)\n",
    "\n",
    "# Create features at product, user and user x product level\n",
    "# Product features\n",
    "print('computing product features')\n",
    "prods = pd.DataFrame()\n",
    "df = priors.groupby('product_id').agg({'order_id': 'count', 'reordered': np.sum, 'add_to_cart_order': np.mean, \n",
    "                                       'order_hour_of_day': np.mean, 'order_dow': np.mean, 'days_since_prior_order': np.mean,\n",
    "                                       'prod_buy_first_time': np.sum, 'prod_buy_second_time': np.sum})\n",
    "prods['prod_ordered'] = df['order_id'].astype(np.int32)\n",
    "prods['prod_reordered'] = df['reordered'].astype(np.float32)\n",
    "prods['prod_reorder_rate'] = (prods.prod_reordered / prods.prod_ordered).astype(np.float32)\n",
    "prods['prod_avg_pos_in_cart'] = df['add_to_cart_order'].astype(np.float32)\n",
    "prods['prod_avg_hour_of_day'] = df['order_hour_of_day'].astype(np.float32)\n",
    "prods['prod_avg_day_of_week'] = df['order_dow'].astype(np.float32)\n",
    "prods['prod_avg_days_since_prior_order'] = df['days_since_prior_order'].astype(np.float32)\n",
    "\n",
    "prods['prod_buy_first_time'] = df['prod_buy_first_time'].astype(np.int32)\n",
    "prods['prod_buy_second_time'] = df['prod_buy_second_time'].astype(np.int32)\n",
    "prods['prod_reorder_prob'] = prods.prod_buy_second_time / prods.prod_buy_first_time\n",
    "prods['prod_reorder_times'] = 1 + prods.prod_reordered / prods.prod_buy_first_time #Look into this in the next verison\n",
    "\n",
    "prods.reset_index(inplace=True)\n",
    "products = products.merge(prods, how = 'left', left_on='product_id', right_on='product_id')\n",
    "products.set_index('product_id', drop=False, inplace=True)\n",
    "del prods\n",
    "del df\n",
    "             \n",
    "### user features\n",
    "print('computing user features')\n",
    "users = pd.DataFrame()\n",
    "                     \n",
    "usr = pd.DataFrame()\n",
    "usr['user_avg_days_bet_orders'] = orders.groupby('user_id')['days_since_prior_order'].mean().astype(np.float32)\n",
    "usr['user_tot_orders'] = orders.groupby('user_id').size().astype(np.int32)\n",
    "usr.reset_index(inplace=True)\n",
    "                   \n",
    "df = priors.groupby('user_id').agg({'order_id': 'count', 'product_id': 'nunique', 'reordered': np.sum, \n",
    "                                    'add_to_cart_order': np.mean})\n",
    "\n",
    "users['user_tot_prods'] = df['order_id'].astype(np.int32)\n",
    "users['user_tot_dist_prods'] = df['product_id'].astype(np.int32)\n",
    "\n",
    "users['user_prod_list'] = priors.groupby('user_id')['product_id'].apply(set)\n",
    "users['user_reorderd_prods'] = df['reordered'].astype(np.int32)\n",
    "users['user_reorderd_rate'] = (users['user_reorderd_prods']/users['user_tot_prods']).astype(np.float32)\n",
    "users.reset_index(inplace=True)\n",
    "users = users.merge(usr, how = 'left', left_on = 'user_id', right_on = 'user_id')\n",
    "users['user_avg_order_size'] = (users.user_tot_prods / users.user_tot_orders).astype(np.float32)\n",
    "users.set_index('user_id', drop=False, inplace=True)\n",
    "print('users shape', users.shape)\n",
    "del usr\n",
    "del df\n",
    "\n",
    "### user X product features\n",
    "priors['user_product'] = priors.user_id.astype(str) + \"-\" + priors.product_id.astype(str)\n",
    "user_product = priors.groupby(['user_product']).agg({'order_id': 'nunique','order_number': 'max', \n",
    "                                                             'add_to_cart_order': np.sum, 'reordered': np.sum, \n",
    "                                                             'days_since_prior_order': np.mean, 'order_hour_of_day': np.mean, 'order_dow': np.mean})\n",
    "user_product['uxp_tot_orders'] = user_product['order_id']\n",
    "user_product['uxp_sum_pos_in_cart']=user_product['add_to_cart_order']\n",
    "\n",
    "user_product['uxp_avg_days_since_prior_order'] = user_product['days_since_prior_order']\n",
    "user_product['uxp_avg_hour_of_day'] = user_product['order_hour_of_day'].astype(np.float32)\n",
    "user_product['uxp_avg_day_of_week'] = user_product['order_dow'].astype(np.float32) # added 4/27\n",
    "\n",
    "user_product['uxp_reordered']=user_product['reordered']\n",
    "user_product['order_number_1'] = user_product['order_number']\n",
    "user_product.drop(['add_to_cart_order','order_id','order_number','order_hour_of_day','order_dow'], axis=1, inplace=True)\n",
    "user_product['order_number'] = user_product['order_number_1']\n",
    "user_product.reset_index(inplace=True)\n",
    "\n",
    "# Get relevant columns for last order for a user X product\n",
    "user_product = user_product.merge(priors[['user_product','user_id','product_id','order_number','order_id','order_hour_of_day','order_dow']], how='left', left_on=['user_product','order_number'], right_on=['user_product','order_number'])\n",
    "user_product['uxp_last_order_id'] = user_product['order_id']\n",
    "user_product['uxp_last_order_number'] = user_product['order_number']\n",
    "user_product['uxp_last_order_hour_of_day'] = user_product['order_hour_of_day']\n",
    "user_product['uxp_last_order_dow'] = user_product['order_dow']\n",
    "user_product.drop(['order_id','order_number','order_number_1','reordered','order_hour_of_day', 'order_dow'], inplace=True, axis=1)\n",
    "user_product.set_index('user_product', drop=False, inplace=True)\n",
    "# user_product.head()\n",
    "\n",
    "\n",
    "### train / test orders ###\n",
    "print('split orders : train, test')\n",
    "test_orders = orders[orders.eval_set == 'test']\n",
    "train_orders = orders[orders.eval_set == 'train']\n",
    "\n",
    "# Assigning index to train data set\n",
    "train.set_index(['order_id', 'product_id'], inplace=True, drop=False)\n",
    "\n",
    "\n",
    "# Create labels and add features to train dataset\n",
    "df_train = train_orders.merge(user_product[['user_id','product_id']], how = 'left', left_on = 'user_id', right_on = 'user_id')\n",
    "print(\"Shape of df_train is :\", df_train.shape)\n",
    "labels = []\n",
    "train_index = set(train.index)  \n",
    "for row in df_train.itertuples():\n",
    "    order_id = row.order_id\n",
    "    product_id = row.product_id\n",
    "    labels += [(order_id, product_id) in train_index]\n",
    "labels = np.array(labels, dtype=np.int8)\n",
    "print(\"Shape of labels array is:\", len(labels))\n",
    "\n",
    "df_train['labels'] = labels\n",
    "\n",
    "print('user related features')\n",
    "df_train['user_tot_orders'] = df_train.user_id.map(users.user_tot_orders)\n",
    "df_train['user_tot_prods'] = df_train.user_id.map(users.user_tot_prods)\n",
    "df_train['user_tot_dist_prods'] = df_train.user_id.map(users.user_tot_dist_prods)\n",
    "df_train['user_avg_days_bet_orders'] = df_train.user_id.map(users.user_avg_days_bet_orders)\n",
    "df_train['user_avg_order_size'] =  df_train.user_id.map(users.user_avg_order_size)\n",
    "df_train['user_reorderd_prods'] =  df_train.user_id.map(users.user_reorderd_prods)\n",
    "df_train['user_reorderd_rate'] =  df_train.user_id.map(users.user_reorderd_rate)\n",
    "                    \n",
    "                     \n",
    "print('order related features')\n",
    "df_train['days_since_ratio'] = df_train.days_since_prior_order / df_train.user_avg_days_bet_orders\n",
    "\n",
    "print('product related features')\n",
    "df_train['aisle_id'] = df_train.product_id.map(products.aisle_id)\n",
    "df_train['department_id'] = df_train.product_id.map(products.department_id)\n",
    "df_train['aisle'] = df_train.product_id.map(products.aisle)\n",
    "df_train['department'] = df_train.product_id.map(products.department)\n",
    "df_train['prod_ordered'] = df_train.product_id.map(products.prod_ordered)\n",
    "df_train['prod_reordered'] = df_train.product_id.map(products.prod_reordered)\n",
    "df_train['prod_reorder_rate'] = df_train.product_id.map(products.prod_reorder_rate)\n",
    "df_train['prod_avg_pos_in_cart'] = df_train.product_id.map(products.prod_avg_pos_in_cart)\n",
    "df_train['prod_avg_hour_of_day'] = df_train.product_id.map(products.prod_avg_hour_of_day)\n",
    "df_train['prod_avg_day_of_week'] = df_train.product_id.map(products.prod_avg_day_of_week)\n",
    "df_train['prod_avg_days_since_prior_order'] = df_train.product_id.map(products.prod_avg_days_since_prior_order)\n",
    "df_train['prod_reorder_prob'] = df_train.product_id.map(products.prod_reorder_prob)\n",
    "df_train['prod_reorder_times'] = df_train.product_id.map(products.prod_reorder_times)\n",
    "\n",
    "# df_train.drop(['user_id'], axis=1, inplace=True)\n",
    "\n",
    "print('user_X_product related features')\n",
    "df_train['user_product'] = df_train.user_id.astype(str) + \"-\" + df_train.product_id.astype(str)\n",
    "df_train['uxp_tot_orders'] = df_train.user_product.map(user_product.uxp_tot_orders)\n",
    "\n",
    "df_train['uxp_last_order_id'] = df_train.user_product.map(user_product.uxp_last_order_id)\n",
    "df_train['uxp_avg_pos_in_cart'] = df_train.user_product.map(user_product.uxp_sum_pos_in_cart)/df_train.uxp_tot_orders\n",
    "df_train['uxp_reordered'] = df_train.user_product.map(user_product.uxp_reordered)\n",
    "\n",
    "df_train['uxp_order_rate'] = df_train.uxp_tot_orders/df_train.user_tot_orders\n",
    "df_train['uxp_reorder_rate'] = df_train.uxp_reordered/df_train.user_reorderd_prods\n",
    "\n",
    "df_train['uxp_avg_days_since_prior_order'] = df_train.user_product.map(user_product.uxp_avg_days_since_prior_order).astype(np.float32)\n",
    "df_train['uxp_avg_hour_of_day'] = df_train.user_product.map(user_product.uxp_avg_hour_of_day).astype(np.float32)\n",
    "df_train['uxp_avg_day_of_week'] = df_train.user_product.map(user_product.uxp_avg_day_of_week).astype(np.float32)\n",
    "\n",
    "df_train['uxp_orders_since_last_order'] = df_train.user_tot_orders - df_train.user_product.map(user_product.uxp_last_order_number)\n",
    "df_train['uxp_delta_hour_vs_last'] = abs(df_train.order_hour_of_day - df_train.user_product.map(user_product.uxp_last_order_hour_of_day)).map(lambda x: min(x, 24-x))\n",
    "# df_train['uxp_delta_day_vs_last'] = abs(df_train.order_dow - df_train.user_product_key.map(user_product.uxp_last_order_dow)).map(lambda x: min(x, 7-x))\n",
    "df_train['uxp_same_dow_as_last_order'] = df_train.user_product.map(user_product.uxp_last_order_dow) == df_train.order_dow\n",
    "\n",
    "\n",
    "features_to_use = ['order_number', 'order_dow','order_hour_of_day', 'days_since_prior_order', 'product_id','user_tot_orders', \n",
    "                'user_tot_prods', 'user_tot_dist_prods', 'user_avg_days_bet_orders', 'user_avg_order_size','user_reorderd_prods',\n",
    "                'user_reorderd_rate', 'aisle','department', 'prod_ordered', 'prod_reordered', 'prod_reorder_rate',\n",
    "                'prod_avg_pos_in_cart', 'prod_avg_hour_of_day', 'prod_avg_day_of_week', 'prod_avg_days_since_prior_order', \n",
    "                'user_product_key', 'uxp_tot_orders', 'uxp_order_rate', 'uxp_last_order_id', 'uxp_avg_pos_in_cart', 'uxp_reordered', 'uxp_reorder_rate',\n",
    "                  'uxp_orders_since_last_order', 'uxp_delta_hour_vs_last', 'uxp_avg_days_since_prior_order', \n",
    "                   'uxp_avg_hour_of_day', 'uxp_avg_day_of_week', 'prod_reorder_prob', 'prod_reorder_times', \n",
    "                   'uxp_order_rate', 'uxp_same_dow_as_last_order']\n",
    "\n",
    "# df_train.head()\n",
    "\n",
    "\n",
    "# Preparation of df_test features\n",
    "df_test = test_orders.merge(user_product[['user_id','product_id']], how = 'left', left_on = 'user_id', right_on = 'user_id')\n",
    "\n",
    "\n",
    "print('user related features')\n",
    "df_test['user_tot_orders'] = df_test.user_id.map(users.user_tot_orders)\n",
    "df_test['user_tot_prods'] = df_test.user_id.map(users.user_tot_prods)\n",
    "df_test['user_tot_dist_prods'] = df_test.user_id.map(users.user_tot_dist_prods)\n",
    "df_test['user_avg_days_bet_orders'] = df_test.user_id.map(users.user_avg_days_bet_orders)\n",
    "df_test['user_avg_order_size'] =  df_test.user_id.map(users.user_avg_order_size)\n",
    "df_test['user_reorderd_prods'] =  df_test.user_id.map(users.user_reorderd_prods)\n",
    "df_test['user_reorderd_rate'] =  df_test.user_id.map(users.user_reorderd_rate)\n",
    "                    \n",
    "                     \n",
    "print('order related features')\n",
    "df_test['days_since_ratio'] = df_test.days_since_prior_order / df_test.user_avg_days_bet_orders\n",
    "\n",
    "print('product related features')\n",
    "df_test['aisle_id'] = df_test.product_id.map(products.aisle_id)\n",
    "df_test['department_id'] = df_test.product_id.map(products.department_id)\n",
    "df_test['aisle'] = df_test.product_id.map(products.aisle)\n",
    "df_test['department'] = df_test.product_id.map(products.department)\n",
    "df_test['prod_ordered'] = df_test.product_id.map(products.prod_ordered)\n",
    "df_test['prod_reordered'] = df_test.product_id.map(products.prod_reordered)\n",
    "df_test['prod_reorder_rate'] = df_test.product_id.map(products.prod_reorder_rate)\n",
    "df_test['prod_avg_pos_in_cart'] = df_test.product_id.map(products.prod_avg_pos_in_cart)\n",
    "df_test['prod_avg_hour_of_day'] = df_test.product_id.map(products.prod_avg_hour_of_day)\n",
    "df_test['prod_avg_day_of_week'] = df_test.product_id.map(products.prod_avg_day_of_week)\n",
    "df_test['prod_avg_days_since_prior_order'] = df_test.product_id.map(products.prod_avg_days_since_prior_order)\n",
    "df_test['prod_reorder_prob'] = df_test.product_id.map(products.prod_reorder_prob)\n",
    "df_test['prod_reorder_times'] = df_test.product_id.map(products.prod_reorder_times)\n",
    "\n",
    "# df_test.drop(['user_id'], axis=1, inplace=True)\n",
    "\n",
    "print('user_X_product related features')\n",
    "df_test['user_product'] = df_test.user_id.astype(str) + \"-\" + df_test.product_id.astype(str)\n",
    "df_test['uxp_tot_orders'] = df_test.user_product.map(user_product.uxp_tot_orders)\n",
    "\n",
    "df_test['uxp_last_order_id'] = df_test.user_product.map(user_product.uxp_last_order_id)\n",
    "df_test['uxp_avg_pos_in_cart'] = df_test.user_product.map(user_product.uxp_sum_pos_in_cart)/df_test.uxp_tot_orders\n",
    "df_test['uxp_reordered'] = df_test.user_product.map(user_product.uxp_reordered)\n",
    "\n",
    "df_test['uxp_order_rate'] = df_test.uxp_tot_orders/df_test.user_tot_orders\n",
    "df_test['uxp_reorder_rate'] = df_test.uxp_reordered/df_test.user_reorderd_prods\n",
    "\n",
    "df_test['uxp_avg_days_since_prior_order'] = df_test.user_product.map(user_product.uxp_avg_days_since_prior_order).astype(np.float32)\n",
    "df_test['uxp_avg_hour_of_day'] = df_test.user_product.map(user_product.uxp_avg_hour_of_day).astype(np.float32)\n",
    "df_test['uxp_avg_day_of_week'] = df_test.user_product.map(user_product.uxp_avg_day_of_week).astype(np.float32)\n",
    "\n",
    "df_test['uxp_orders_since_last_order'] = df_test.user_tot_orders - df_test.user_product.map(user_product.uxp_last_order_number)\n",
    "df_test['uxp_delta_hour_vs_last'] = abs(df_test.order_hour_of_day - df_test.user_product.map(user_product.uxp_last_order_hour_of_day)).map(lambda x: min(x, 24-x))\n",
    "# df_test['uxp_delta_day_vs_last'] = abs(df_test.order_dow - df_test.user_product_key.map(user_product.uxp_last_order_dow)).map(lambda x: min(x, 7-x))\n",
    "df_test['uxp_same_dow_as_last_order'] = df_test.user_product.map(user_product.uxp_last_order_dow) == df_test.order_dow\n",
    "\n",
    "gc.collect()\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Light GBM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svmem(total=270008086528, available=127754268672, percent=52.7, used=137012580352, free=29907632128, active=148541300736, inactive=85502771200, buffers=896446464, cached=102191427584, shared=734601216, slab=2482016256)\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "print(psutil.virtual_memory())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('/axp/buanalytics/cscust360/dev/Anu/Kaggle/df_train.csv')\n",
    "df_test.to_csv('/axp/buanalytics/cscust360/dev/Anu/Kaggle/df_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8474661, 43)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8474661, 44)\n",
      "(4833292, 43)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('/axp/buanalytics/cscust360/dev/Anu/Kaggle/df_train.csv')\n",
    "df_test = pd.read_csv('/axp/buanalytics/cscust360/dev/Anu/Kaggle/df_test.csv')\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8474661, 43)\n",
      "(4833292, 42)\n"
     ]
    }
   ],
   "source": [
    "df_train.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "df_test.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "formating for lgb\n",
      "light GBM train :-)\n",
      "light GBM predict\n"
     ]
    }
   ],
   "source": [
    "features_to_use = ['order_number', 'order_dow','order_hour_of_day', 'days_since_prior_order',\n",
    "                   'user_tot_orders', 'user_tot_prods', 'user_tot_dist_prods','user_avg_days_bet_orders', \n",
    "                   'user_avg_order_size','user_reorderd_prods', 'user_reorderd_rate', 'days_since_ratio',\n",
    "                   'aisle_id', 'department_id','prod_ordered','prod_reordered', 'prod_reorder_rate', \n",
    "                   'prod_avg_pos_in_cart','prod_avg_hour_of_day', 'prod_avg_day_of_week','prod_avg_days_since_prior_order', \n",
    "                   'prod_reorder_prob','prod_reorder_times', 'uxp_tot_orders','uxp_last_order_id', \n",
    "                   'uxp_avg_pos_in_cart', 'uxp_reordered','uxp_order_rate', 'uxp_reorder_rate', 'uxp_avg_days_since_prior_order',\n",
    "                   'uxp_avg_hour_of_day', 'uxp_avg_day_of_week', 'uxp_orders_since_last_order', 'uxp_delta_hour_vs_last',\n",
    "                   'uxp_same_dow_as_last_order']\n",
    "\n",
    "features_to_use_1 = ['user_tot_orders', 'user_tot_prods', 'user_tot_dist_prods', 'user_avg_days_bet_orders', \n",
    "                     'user_avg_order_size', 'order_hour_of_day', 'days_since_prior_order', 'days_since_ratio','aisle_id', \n",
    "                     'department_id','prod_ordered', 'prod_reordered', 'prod_reorder_rate','uxp_tot_orders', 'uxp_order_rate', \n",
    "                     'uxp_avg_pos_in_cart','uxp_reorder_rate','uxp_orders_since_last_order', 'uxp_delta_hour_vs_last']\n",
    "\n",
    "print('formating for lgb')\n",
    "d_train = lgb.Dataset(df_train[features_to_use], label=df_train['labels'],categorical_feature=['aisle_id', 'department_id'])\n",
    "# del df_train\n",
    "\n",
    "params = {'task': 'train', 'boosting_type': 'gbdt', 'objective': 'binary', 'metric': {'binary_logloss'}, 'num_leaves': 96,\n",
    "          'max_depth': 10, 'feature_fraction': 0.9, 'bagging_fraction': 0.95, 'bagging_freq': 5\n",
    "}\n",
    "ROUNDS = 100\n",
    "\n",
    "print('light GBM train :-)')\n",
    "bst = lgb.train(params, d_train, ROUNDS)\n",
    "# lgb.plot_importance(bst, figsize=(9,20))\n",
    "del d_train\n",
    "\n",
    "print('light GBM predict')\n",
    "preds = bst.predict(df_test[features_to_use])\n",
    "\n",
    "df_test['pred'] = preds\n",
    "\n",
    "TRESHOLD = 0.22  # guess, should be tuned with crossval on a subset of train data\n",
    "\n",
    "d = dict()\n",
    "for row in df_test.itertuples():\n",
    "    if row.pred > TRESHOLD:\n",
    "        try:\n",
    "            d[row.order_id] += ' ' + str(row.product_id)\n",
    "        except:\n",
    "            d[row.order_id] = str(row.product_id)\n",
    "\n",
    "for order in test_orders.order_id:\n",
    "    if order not in d:\n",
    "        d[order] = 'None'\n",
    "\n",
    "sub = pd.DataFrame.from_dict(d, orient='index')\n",
    "\n",
    "sub.reset_index(inplace=True)\n",
    "sub.columns = ['order_id', 'products']\n",
    "sub.to_csv('sub_lgbm_15Jun_allvars.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Random Forest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imputation done\n",
      "TRAIN DATA SIZE:  (8474661, 38)\n",
      "TEST DATA SIZE:  (4833292, 38)\n"
     ]
    }
   ],
   "source": [
    "numeric = ['user_tot_orders', 'user_tot_prods', 'user_tot_dist_prods', 'user_avg_days_bet_orders', 'user_avg_order_size', \n",
    "           'order_hour_of_day', 'days_since_prior_order', 'days_since_ratio', 'prod_ordered', 'prod_reordered', 'prod_reorder_rate',\n",
    "           'uxp_tot_orders', 'uxp_order_rate', 'uxp_avg_pos_in_cart','uxp_reorder_rate','uxp_orders_since_last_order', 'uxp_delta_hour_vs_last']\n",
    "\n",
    "impute_values = {}\n",
    "for col in numeric:\n",
    "    try:\n",
    "        impute_values[col] = df_train[col].median()\n",
    "    except:\n",
    "        pass\n",
    "# features_to_use_1 = numeric + categorical\n",
    "df_train[numeric] = df_train[numeric].fillna(impute_values)\n",
    "del impute_values\n",
    "\n",
    "impute_values = {}\n",
    "for col in numeric:\n",
    "    try:\n",
    "        impute_values[col] = df_test[col].median()\n",
    "    except:\n",
    "        pass\n",
    "# features_to_use_1 = numeric + categorical\n",
    "df_test[numeric] = df_test[numeric].fillna(impute_values)\n",
    "print(\"imputation done\")\n",
    "\n",
    "\n",
    "features_to_use_1 = ['user_tot_orders', 'user_tot_prods', 'user_tot_dist_prods', 'user_avg_days_bet_orders', \n",
    "                     'user_avg_order_size', 'order_hour_of_day', 'days_since_prior_order', 'days_since_ratio',\n",
    "                     'department','prod_ordered', 'prod_reordered', 'prod_reorder_rate','uxp_tot_orders', 'uxp_order_rate', \n",
    "                     'uxp_avg_pos_in_cart','uxp_reorder_rate','uxp_orders_since_last_order', 'uxp_delta_hour_vs_last']\n",
    "X_train= pd.get_dummies(df_train.loc[:,features_to_use_1])\n",
    "variables = X_train.columns.tolist()\n",
    "print('TRAIN DATA SIZE: ', X_train.shape)\n",
    "# X_train.to_csv(\"/axp/buanalytics/cscust360/dev/Anu/Kaggle/X_train_rem_aisle.csv\")\n",
    "y_train = df_train['labels']\n",
    "# y_train.to_csv(\"/axp/buanalytics/cscust360/dev/Anu/Kaggle/y_train_rem_aisle.csv\")\n",
    "# del df_train\n",
    "\n",
    "X_test = pd.get_dummies(df_test.loc[:,features_to_use_1])\n",
    "test_cols = set(X_test.columns)\n",
    "columns_not_present = set(variables) - test_cols\n",
    "for col in columns_not_present:\n",
    "    X_test[col] = 0\n",
    "X_test = X_test[variables]\n",
    "print('TEST DATA SIZE: ', X_test.shape)\n",
    "# X_test.to_csv(\"/axp/buanalytics/cscust360/dev/Anu/Kaggle/X_test_rem_aisle.csv\")\n",
    "# del df_test\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "for column in X_train.columns:\n",
    "    if X_train[column].dtype == 'float64':\n",
    "        X_train[column] = X_train[column].astype(np.float32)\n",
    "y_train = y_train.astype(np.int8)\n",
    "for column in X_test.columns:\n",
    "    if X_test[column].dtype == 'float64':\n",
    "        X_test[column] = X_test[column].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': [5, 7], 'n_estimators': [50, 70], 'max_features': ['auto']}\n",
      "{'max_depth': 7, 'n_estimators': 70, 'max_features': 'auto'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [50,70]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto'] #'sqrt'\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [5,7]\n",
    "# max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [2, 4]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "param_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth}\n",
    "#                'min_samples_split': min_samples_split,\n",
    "#                'min_samples_leaf': min_samples_leaf,\n",
    "#                'bootstrap': bootstrap}\n",
    "\n",
    "print(param_grid)\n",
    "\n",
    "rfc = RandomForestClassifier(random_state = 42, n_jobs = 3)\n",
    "cv_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, scoring = 'roc_auc')\n",
    "cv_rfc.fit(X_train.values, y_train.values)\n",
    "\n",
    "# print results\n",
    "print(cv_rfc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9070941008731794\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>eval_set</th>\n",
       "      <th>order_number</th>\n",
       "      <th>order_dow</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "      <th>product_id</th>\n",
       "      <th>user_tot_orders</th>\n",
       "      <th>user_tot_prods</th>\n",
       "      <th>...</th>\n",
       "      <th>uxp_order_rate</th>\n",
       "      <th>uxp_reorder_rate</th>\n",
       "      <th>uxp_avg_days_since_prior_order</th>\n",
       "      <th>uxp_avg_hour_of_day</th>\n",
       "      <th>uxp_avg_day_of_week</th>\n",
       "      <th>uxp_orders_since_last_order</th>\n",
       "      <th>uxp_delta_hour_vs_last</th>\n",
       "      <th>uxp_same_dow_as_last_order</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2774568</td>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1005</td>\n",
       "      <td>13</td>\n",
       "      <td>88</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.044775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2774568</td>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12845</td>\n",
       "      <td>13</td>\n",
       "      <td>88</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.040813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2774568</td>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14992</td>\n",
       "      <td>13</td>\n",
       "      <td>88</td>\n",
       "      <td>...</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.095523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2774568</td>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15143</td>\n",
       "      <td>13</td>\n",
       "      <td>88</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.041981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2774568</td>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16797</td>\n",
       "      <td>13</td>\n",
       "      <td>88</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.162997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id  user_id eval_set  order_number  order_dow  order_hour_of_day  \\\n",
       "0   2774568        3     test            13          5                 15   \n",
       "1   2774568        3     test            13          5                 15   \n",
       "2   2774568        3     test            13          5                 15   \n",
       "3   2774568        3     test            13          5                 15   \n",
       "4   2774568        3     test            13          5                 15   \n",
       "\n",
       "   days_since_prior_order  product_id  user_tot_orders  user_tot_prods  \\\n",
       "0                    11.0        1005               13              88   \n",
       "1                    11.0       12845               13              88   \n",
       "2                    11.0       14992               13              88   \n",
       "3                    11.0       15143               13              88   \n",
       "4                    11.0       16797               13              88   \n",
       "\n",
       "     ...     uxp_order_rate  uxp_reorder_rate  uxp_avg_days_since_prior_order  \\\n",
       "0    ...           0.076923          0.000000                            17.0   \n",
       "1    ...           0.076923          0.000000                            20.0   \n",
       "2    ...           0.153846          0.018182                             7.0   \n",
       "3    ...           0.076923          0.000000                             NaN   \n",
       "4    ...           0.230769          0.036364                             7.0   \n",
       "\n",
       "   uxp_avg_hour_of_day  uxp_avg_day_of_week  uxp_orders_since_last_order  \\\n",
       "0                 16.0             3.000000                            3   \n",
       "1                 18.0             2.000000                            9   \n",
       "2                 15.5             0.000000                            6   \n",
       "3                 14.0             1.000000                           12   \n",
       "4                 15.0             0.333333                            4   \n",
       "\n",
       "   uxp_delta_hour_vs_last  uxp_same_dow_as_last_order pred pred_prob  \n",
       "0                       1                       False    0  0.044775  \n",
       "1                       3                       False    0  0.040813  \n",
       "2                       0                       False    0  0.095523  \n",
       "3                       1                       False    0  0.041981  \n",
       "4                       1                       False    0  0.162997  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(random_state = 42, n_jobs = 3, n_estimators = 70, \n",
    "                             max_features = 'auto', max_depth = 7)\n",
    "rfc.fit(X_train.values, y_train.values)\n",
    "y_test_pred = rfc.predict(X_test.values)\n",
    "print(accuracy_score(rfc.predict(X_train.values), y_train.values))\n",
    "df_test['pred'] = y_test_pred\n",
    "prob = pd.DataFrame(rfc.predict_proba(X_test.values), columns=rfc.classes_)\n",
    "df_test['pred_prob'] = prob[1]\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.22  # guess, should be tuned with crossval on a subset of train data\n",
    "\n",
    "d = dict()\n",
    "for row in df_test.itertuples():\n",
    "    if row.pred > THRESHOLD:\n",
    "        try:\n",
    "            d[row.order_id] += ' ' + str(row.product_id)\n",
    "        except:\n",
    "            d[row.order_id] = str(row.product_id)\n",
    "\n",
    "for order in test_orders.order_id:\n",
    "    if order not in d:\n",
    "        d[order] = 'None'\n",
    "\n",
    "sub = pd.DataFrame.from_dict(d, orient='index')\n",
    "\n",
    "sub.reset_index(inplace=True)\n",
    "sub.columns = ['order_id', 'products']\n",
    "sub.to_csv('sub_rfc_17June.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. XGBoost Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imputation done\n",
      "TRAIN DATA SIZE:  (8474661, 38)\n",
      "TEST DATA SIZE:  (4833292, 38)\n"
     ]
    }
   ],
   "source": [
    "numeric = ['user_tot_orders', 'user_tot_prods', 'user_tot_dist_prods', 'user_avg_days_bet_orders', 'user_avg_order_size', \n",
    "           'order_hour_of_day', 'days_since_prior_order', 'days_since_ratio', 'prod_ordered', 'prod_reordered', 'prod_reorder_rate',\n",
    "           'uxp_tot_orders', 'uxp_order_rate', 'uxp_avg_pos_in_cart','uxp_reorder_rate','uxp_orders_since_last_order', 'uxp_delta_hour_vs_last']\n",
    "\n",
    "impute_values = {}\n",
    "for col in numeric:\n",
    "    try:\n",
    "        impute_values[col] = df_train[col].median()\n",
    "    except:\n",
    "        pass\n",
    "# features_to_use_1 = numeric + categorical\n",
    "df_train[numeric] = df_train[numeric].fillna(impute_values)\n",
    "del impute_values\n",
    "\n",
    "impute_values = {}\n",
    "for col in numeric:\n",
    "    try:\n",
    "        impute_values[col] = df_test[col].median()\n",
    "    except:\n",
    "        pass\n",
    "# features_to_use_1 = numeric + categorical\n",
    "df_test[numeric] = df_test[numeric].fillna(impute_values)\n",
    "print(\"imputation done\")\n",
    "\n",
    "features_to_use_1 = ['user_tot_orders', 'user_tot_prods', 'user_tot_dist_prods', 'user_avg_days_bet_orders', \n",
    "                     'user_avg_order_size', 'order_hour_of_day', 'days_since_prior_order', 'days_since_ratio',\n",
    "                     'department','prod_ordered', 'prod_reordered', 'prod_reorder_rate','uxp_tot_orders', 'uxp_order_rate', \n",
    "                     'uxp_avg_pos_in_cart','uxp_reorder_rate','uxp_orders_since_last_order', 'uxp_delta_hour_vs_last']\n",
    "X_train= pd.get_dummies(df_train.loc[:,features_to_use_1])\n",
    "variables = X_train.columns.tolist()\n",
    "print('TRAIN DATA SIZE: ', X_train.shape)\n",
    "# X_train.to_csv(\"/axp/buanalytics/cscust360/dev/Anu/Kaggle/X_train_rem_aisle.csv\")\n",
    "y_train = df_train['labels']\n",
    "# y_train.to_csv(\"/axp/buanalytics/cscust360/dev/Anu/Kaggle/y_train_rem_aisle.csv\")\n",
    "# del df_train\n",
    "\n",
    "X_test = pd.get_dummies(df_test.loc[:,features_to_use_1])\n",
    "test_cols = set(X_test.columns)\n",
    "columns_not_present = set(variables) - test_cols\n",
    "for col in columns_not_present:\n",
    "    X_test[col] = 0\n",
    "X_test = X_test[variables]\n",
    "print('TEST DATA SIZE: ', X_test.shape)\n",
    "# X_test.to_csv(\"/axp/buanalytics/cscust360/dev/Anu/Kaggle/X_test_rem_aisle.csv\")\n",
    "# del df_test\n",
    "gc.collect()\n",
    "\n",
    "for column in X_train.columns:\n",
    "    if X_train[column].dtype == 'float64':\n",
    "        X_train[column] = X_train[column].astype(np.float32)\n",
    "y_train = y_train.astype(np.int8)\n",
    "for column in X_test.columns:\n",
    "    if X_test[column].dtype == 'float64':\n",
    "        X_test[column] = X_test[column].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svmem(total=540687081472, available=233800704000, percent=56.8, used=300302757888, free=46918955008, active=351852785664, inactive=129511563264, buffers=1312206848, cached=192153161728, shared=1223315456, slab=3933052928)\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "print(psutil.virtual_memory())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.830810 using {'max_depth': 5, 'learning_rate': 0.2, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning for XGBoost model\n",
    "xgb = XGBClassifier(objective = 'binary:logistic')\n",
    "\n",
    "param_dist = {'n_estimators': [50, 70],\n",
    "              'learning_rate': [0.01, 0.2],\n",
    "#               'subsample': [stats.uniform(]0.3, 0.9),\n",
    "              'max_depth': [3, 5]\n",
    "#               'colsample_bytree': [0.5, 0.7],\n",
    "#               'min_child_weight': [1, 2]\n",
    "             }\n",
    "\n",
    "# numFolds = 5\n",
    "# kfold_5 = cross_validation.KFold(n = len(X), shuffle = True, n_folds = numFolds)\n",
    "\n",
    "clf = RandomizedSearchCV(xgb, param_distributions = param_dist, n_iter = 2, cv = 3,\n",
    "                         scoring = 'roc_auc', error_score = 0, verbose = 3, n_jobs = -1)\n",
    "\n",
    "clf_result = clf.fit(X_train.values, y_train.values)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (clf_result.best_score_, clf_result.best_params_))\n",
    "means = clf_result.cv_results_['mean_test_score']\n",
    "stds = clf_result.cv_results_['std_test_score']\n",
    "params = clf_result.cv_results_['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:03:33] WARNING: /workspace/src/learner.cc:686: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n",
      "0.9093839859789082\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "xgb = XGBClassifier(objective='binary:logistic', n_estimators=50, max_depth = 5, learning_rate=0.2)\n",
    "xgb.fit(X_train.values, y_train.values)\n",
    "# del X_train\n",
    "# del y_train\n",
    "gc.collect()\n",
    "y_test_pred = xgb.predict(X_test.values)\n",
    "# xgb.save_model('xgb_model_16Jun.model')\n",
    "print(accuracy_score(xgb.predict(X_train.values), y_train.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>eval_set</th>\n",
       "      <th>order_number</th>\n",
       "      <th>order_dow</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "      <th>product_id</th>\n",
       "      <th>user_tot_orders</th>\n",
       "      <th>user_tot_prods</th>\n",
       "      <th>...</th>\n",
       "      <th>uxp_order_rate</th>\n",
       "      <th>uxp_reorder_rate</th>\n",
       "      <th>uxp_avg_days_since_prior_order</th>\n",
       "      <th>uxp_avg_hour_of_day</th>\n",
       "      <th>uxp_avg_day_of_week</th>\n",
       "      <th>uxp_orders_since_last_order</th>\n",
       "      <th>uxp_delta_hour_vs_last</th>\n",
       "      <th>uxp_same_dow_as_last_order</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2774568</td>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1005</td>\n",
       "      <td>13</td>\n",
       "      <td>88</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.054716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2774568</td>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12845</td>\n",
       "      <td>13</td>\n",
       "      <td>88</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.026354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2774568</td>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14992</td>\n",
       "      <td>13</td>\n",
       "      <td>88</td>\n",
       "      <td>...</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.092646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2774568</td>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15143</td>\n",
       "      <td>13</td>\n",
       "      <td>88</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2774568</td>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16797</td>\n",
       "      <td>13</td>\n",
       "      <td>88</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.168640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id  user_id eval_set  order_number  order_dow  order_hour_of_day  \\\n",
       "0   2774568        3     test            13          5                 15   \n",
       "1   2774568        3     test            13          5                 15   \n",
       "2   2774568        3     test            13          5                 15   \n",
       "3   2774568        3     test            13          5                 15   \n",
       "4   2774568        3     test            13          5                 15   \n",
       "\n",
       "   days_since_prior_order  product_id  user_tot_orders  user_tot_prods  \\\n",
       "0                    11.0        1005               13              88   \n",
       "1                    11.0       12845               13              88   \n",
       "2                    11.0       14992               13              88   \n",
       "3                    11.0       15143               13              88   \n",
       "4                    11.0       16797               13              88   \n",
       "\n",
       "     ...     uxp_order_rate  uxp_reorder_rate  uxp_avg_days_since_prior_order  \\\n",
       "0    ...           0.076923          0.000000                            17.0   \n",
       "1    ...           0.076923          0.000000                            20.0   \n",
       "2    ...           0.153846          0.018182                             7.0   \n",
       "3    ...           0.076923          0.000000                             NaN   \n",
       "4    ...           0.230769          0.036364                             7.0   \n",
       "\n",
       "   uxp_avg_hour_of_day  uxp_avg_day_of_week  uxp_orders_since_last_order  \\\n",
       "0                 16.0             3.000000                            3   \n",
       "1                 18.0             2.000000                            9   \n",
       "2                 15.5             0.000000                            6   \n",
       "3                 14.0             1.000000                           12   \n",
       "4                 15.0             0.333333                            4   \n",
       "\n",
       "   uxp_delta_hour_vs_last  uxp_same_dow_as_last_order pred pred_prob  \n",
       "0                       1                       False    0  0.054716  \n",
       "1                       3                       False    0  0.026354  \n",
       "2                       0                       False    0  0.092646  \n",
       "3                       1                       False    0  0.024793  \n",
       "4                       1                       False    0  0.168640  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['pred'] = y_test_pred\n",
    "prob = pd.DataFrame(xgb.predict_proba(X_test.values), columns=xgb.classes_)\n",
    "df_test['pred_prob'] = prob[1]\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = dict()\n",
    "THRESHOLD = 0.3  # guess, should be tuned with crossval on a subset of train data\n",
    "for row in df_test.itertuples():\n",
    "    if row.pred_prob > THRESHOLD:\n",
    "        try:\n",
    "            d[row.order_id] += ' ' + str(row.product_id)\n",
    "        except:\n",
    "            d[row.order_id] = str(row.product_id)\n",
    "            \n",
    "for order in test_orders.order_id:\n",
    "    if order not in d:\n",
    "        d[order] = 'None'\n",
    "        \n",
    "sub = pd.DataFrame.from_dict(d, orient='index')\n",
    "sub.reset_index(inplace=True)\n",
    "sub.columns = ['order_id', 'products']\n",
    "sub.to_csv('sub_xgboost_17Jun_30.csv', index=False)\n",
    "sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 2)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = dict()\n",
    "THRESHOLD = 0.22  # guess, should be tuned with crossval on a subset of train data\n",
    "for row in df_test.itertuples():\n",
    "    if row.pred_prob > THRESHOLD:\n",
    "        try:\n",
    "            d[row.order_id] += ' ' + str(row.product_id)\n",
    "        except:\n",
    "            d[row.order_id] = str(row.product_id)\n",
    "            \n",
    "for order in test_orders.order_id:\n",
    "    if order not in d:\n",
    "        d[order] = 'None'\n",
    "        \n",
    "sub = pd.DataFrame.from_dict(d, orient='index')\n",
    "sub.reset_index(inplace=True)\n",
    "sub.columns = ['order_id', 'products']\n",
    "sub.to_csv('sub_xgboost_17Jun_22.csv', index=False)\n",
    "sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "      <th>Variable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.446633</td>\n",
       "      <td>uxp_order_rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.179027</td>\n",
       "      <td>uxp_orders_since_last_order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.099416</td>\n",
       "      <td>uxp_reorder_rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.072619</td>\n",
       "      <td>uxp_tot_orders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.049470</td>\n",
       "      <td>prod_reorder_rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.037876</td>\n",
       "      <td>department</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.026100</td>\n",
       "      <td>days_since_prior_order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.014380</td>\n",
       "      <td>days_since_ratio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.013321</td>\n",
       "      <td>prod_reordered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.012223</td>\n",
       "      <td>uxp_delta_hour_vs_last</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.007514</td>\n",
       "      <td>user_tot_prods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.007360</td>\n",
       "      <td>user_avg_days_bet_orders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.007177</td>\n",
       "      <td>user_avg_order_size</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.006647</td>\n",
       "      <td>user_tot_dist_prods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.006551</td>\n",
       "      <td>user_tot_orders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005624</td>\n",
       "      <td>prod_ordered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.005605</td>\n",
       "      <td>uxp_avg_pos_in_cart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002457</td>\n",
       "      <td>order_hour_of_day</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Importance                     Variable\n",
       "14    0.446633               uxp_order_rate\n",
       "15    0.179027  uxp_orders_since_last_order\n",
       "16    0.099416             uxp_reorder_rate\n",
       "17    0.072619               uxp_tot_orders\n",
       "5     0.049470            prod_reorder_rate\n",
       "2     0.037876                   department\n",
       "0     0.026100       days_since_prior_order\n",
       "1     0.014380             days_since_ratio\n",
       "6     0.013321               prod_reordered\n",
       "13    0.012223       uxp_delta_hour_vs_last\n",
       "11    0.007514               user_tot_prods\n",
       "7     0.007360     user_avg_days_bet_orders\n",
       "8     0.007177          user_avg_order_size\n",
       "9     0.006647          user_tot_dist_prods\n",
       "10    0.006551              user_tot_orders\n",
       "4     0.005624                 prod_ordered\n",
       "12    0.005605          uxp_avg_pos_in_cart\n",
       "3     0.002457            order_hour_of_day"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "categorical_all = ['department']\n",
    "\n",
    "def de_one_hot_encode(s):\n",
    "    for col in categorical_all:\n",
    "        if(col in s):\n",
    "            return col\n",
    "    return s\n",
    "\n",
    "# Get variable importance\n",
    "variables = X_train.columns.tolist()\n",
    "features = pd.DataFrame({'Importance':xgb.feature_importances_ , 'Variable':variables})\n",
    "features['Variable'] = features['Variable'].apply(de_one_hot_encode)\n",
    "features = features.groupby('Variable').sum().reset_index()\n",
    "features = features.sort_values('Importance', ascending=False )\n",
    "features = features[['Importance', 'Variable']]\n",
    "display(features)\n",
    "features.to_csv('feature_importances_xgboost_21Jun.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
